---
title: "QA and Common Pitfalls"
author: "Fluent Data"
date: "2023-06-16"
output: 
  html_document: 
    keep_md: yes
description: "A guide to quality assurance and common pitfalls in R programming for air quality data analysis."
---

## Quality Assurance

Quality assurance (QA) is essential in data analysis to ensure that the data in your dataset is accurate and reliable. Regardless of the software package you are using, the fundamental idea of QA remains the same. In this guide, we will explore some tips for conducting QA in R for air quality data analysis.

```{r setup, message=FALSE, warning=FALSE}

# Load necessary packages and sample air quality dataset
library(region5air)
data(airdata)

```

### Data Types

After importing your data, it is important to confirm that the variables are in the expected format. The `str()` function can be used to display the structure of your dataset and provide information on variable types.

```{r}

str(airdata)

```

### Handling "Illegal" Data

"Illegal" data refers to values that are not conceivably possible and may have ended up in your dataset by accident. In this example, we will replace any negative ozone values with `NA`.

```{r}

airdata$ozone[airdata$ozone < 0] <- NA

```

### Detecting Outliers

Outliers are data points that deviate significantly from the rest of the dataset and can have a significant impact on analysis results. To identify outliers, we can start by examining the summary of the data and paying attention to the minimum and maximum values. Visual inspection using boxplots can also be helpful in detecting unusual patterns or extreme values.

```{r}

boxplot(airdata$ozone)

```

Another approach to detecting outliers is by conducting outlier tests. The `outlier()` function from the `psych` package can be used to calculate the Mahalanobis distance, which identifies multivariate records that appear to be unusual.

```{r}
library(psych)

outliers <- outlier(airdata[, c("ozone", "temp", "solar")], plot=TRUE)

```

### Handling Missing Data

Missing data can occur in a dataset for various reasons and needs to be properly addressed. It is important to use the value `NA` to represent missing data in R. In this example, we will demonstrate how to replace specific codes representing missing values with `NA`.

```{r}

missing_codes <- c(-99, -999)

my_temp <- c(81, 82, 75, 90, -99, 74, 76,-99, 68)
my_temp[my_temp %in% missing_codes] <- NA

my_temp

```

Alternatively, when reading in a file with missing codes, you can use the `na.strings` argument in functions such as `read.csv()` or `read.table()`.

```{r}
read.table(na.strings = c('-99','-999'), text = '
  1      5
  5      8
  3    -99
-99      3
  5      4
  9   -999
  7      6
  5      1
  9      3
-99      4
')

```

### Handling Missing Data with the `zoo` Package

The `zoo` package provides functions that can help replace missing values with values that make sense for analysis when missing data is not acceptable.

```{r}
# Install the zoo package if necessary
# install.packages("zoo")
library(zoo)
```

The `na.locf()` function replaces each `NA` in a series with the most recent non-`NA` value that occurred prior to it.

```{r}
my_temp
na.locf(my_temp)  

```

The `na.approx()` function replaces each `NA` in a series with a linearly interpolated value based on the adjacent non-`NA` values.

```{r}
my_temp
na.approx(my_temp) 

```

The `na.spline()` function replaces each `NA` in a series with a cubic spline interpolated value.

```{r}
my_temp
round(na.spline(my_temp)) 

```

### Other QA Considerations

In addition to the concepts covered above, it is important to consider the following aspects of QA in R programming:

- Neglecting due diligence when choosing a package, such as not verifying the qualifications of the package authors.
- Misusing packages or functions due to not reading the documentation or understanding their intended purpose.
- Inadequate checking of work, including appropriate testing procedures to identify errors.

To prevent repeated errors and ensure the accuracy of your analysis, it is recommended to learn how to use the `testthat` package for automated testing. The `testthat` package allows you to set up tests that check for errors and validate the expected results.

## Common Pitfalls

While using R for data analysis, it is common to encounter some pitfalls. The following are a few common pitfalls along with tips to overcome them:

- **R Inferno**: The [R Inferno](https://www.burns-stat.com/pages/Tutor/R_inferno.pdf) is a great resource that addresses common R errors, although it may be slightly outdated.
- **Syntax Errors**: If you encounter a syntax error, it means that R cannot understand the command you entered. Syntax errors are often caused by missing commas, unmatched parentheses, or incorrect closing braces.
- **Object-Not-Found Errors**: Object-not-found errors occur when the name of an object is not spelled correctly or the capitalization is incorrect. Another possible cause is that the package or file containing the object is not on the search list.

### Exercises

1. Calculate the mean and standard deviation of the "wind" variable in the `airdata` dataset.
2. Create a scatter plot between the "ozone" and "temperature" variables in the `airdata` dataset.
3. Replace missing values represented by -999 with the mean value of the "solar" variable in the `airdata` dataset.

### Multiple Choice Questions

1. What function can be used to check the structure of a dataset in R?
    - A. `summary()`
    - B. `str()`
    - C. `head()`
    - D. `colnames()`

2. Which package provides functions to handle missing values in R?
    - A. `dplyr`
    - B. `tidyr`
    - C. `zoo`
    - D. `ggplot2`

3. How can outliers be detected in a dataset?
    - A. By examining summary statistics
    - B. By visual inspection using boxplots
    - C. By conducting outlier tests
    - D. All of the above

4. What is the purpose of automated testing in R?
    - A. To check for obvious errors
    - B. To validate expected results
    - C. To prevent repeated errors
    - D. All of the above

#### Overview of Revisions

- Added necessary front matter such as title, author, date, and description.
- Removed unnecessary code chunks and improved the code formatting.
- Added explanations and examples for each concept covered.
- Revised the structure of the document to improve readability.
- Clarified terminology and added relevant examples in code blocks.
- Updated information on best practices and techniques.
- Added exercises and multiple-choice questions to test understanding.